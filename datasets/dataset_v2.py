import os
import torch
from torch.utils.data import Dataset
import numpy as np
import nibabel as nib
from utils.monai_downsampling_reshape import monai_resize


class BraTSDataset(Dataset):
    def __init__(self, data_dir, case_list, transform=None):
        self.data_dir = data_dir
        self.case_list = case_list
        self.transform = transform
        self.modalities = ['t1c', 't1n', 't2f', 't2w']
        # self.aug_num = [0,1,2,3,4]

    def __len__(self):
        return len(self.case_list)

    def __getitem__(self, idx):
        case = self.case_list[idx]
        case_path = os.path.join(self.data_dir, case)

        # --- ì´ë¯¸ì§€ ë¡œë”© ë° MONAI ë¦¬ì‚¬ì´ì¦ˆ ---
        images = []
        for mod in self.modalities:
            img = nib.load(os.path.join(case_path, f'{case}-{mod}.nii.gz')).get_fdata().astype(np.float32)
            images.append(img)
        images = np.stack(images, axis=0)  # [4, H, W, D]
        images = monai_resize(images, is_mask=False)  # [4, 128, 128, 32]4

        # --- ì •ê·œí™” ---
        images = (images - images.mean()) / (images.std() + 1e-8)

        # --- ë³€í™˜ ---
        images = torch.from_numpy(images).float()

        # --- ë§ˆìŠ¤í¬ ë¡œë”© (GTëŠ” ì›ë³¸ í•´ìƒë„ ìœ ì§€) ---
        seg = nib.load(os.path.join(case_path, f'{case}-seg.nii.gz')).get_fdata().astype(np.int64)
        seg = np.clip(seg, 0, 4)

        # --- ë³€í™˜ ---
        seg = torch.from_numpy(seg).long()

        if self.transform:
            images, seg = self.transform(images, seg)

        return images, seg

import numpy as np
import torch
from collections import Counter

def compute_class_distribution(dataset, max_samples=20):
    label_counter = Counter()
    total_voxels = 0

    for i in range(min(len(dataset), max_samples)):
        _, seg = dataset[i]  # seg: torch.Tensor [H, W, D]
        labels, counts = torch.unique(seg, return_counts=True)

        for label, count in zip(labels.tolist(), counts.tolist()):
            label_counter[int(label)] += count
            total_voxels += count

    print("ğŸ“Š í´ë˜ìŠ¤ë³„ ë¹„ìœ¨ (ìƒìœ„ {}ê°œ ìƒ˜í”Œ ê¸°ì¤€):".format(max_samples))
    for label in sorted(label_counter.keys()):
        ratio = label_counter[label] / total_voxels * 100
        print(f"  ğŸ”¹ í´ë˜ìŠ¤ {label}: {label_counter[label]:,} voxels ({ratio:.2f}%)")

# ==========================
# ğŸ” ì§ì ‘ ì‹¤í–‰í•  ê²½ìš° í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ==========================
if __name__ == "__main__":
    from torch.utils.data import DataLoader

    data_dir = "../data/BraTS-PEDs2024_Training"
    case_list = sorted([
        name for name in os.listdir(data_dir)
        if os.path.isdir(os.path.join(data_dir, name)) and not name.startswith(".")
    ])  # ìƒìœ„ 10ê°œ ì¼€ì´ìŠ¤ë§Œ í™•ì¸
    samples = len(case_list)
    dataset = BraTSDataset(data_dir, case_list)

    compute_class_distribution(dataset, max_samples=samples)  # 20ê°œë§Œ í™•ì¸
    all_labels = []
    for i in range(len(dataset)):
        img, seg = dataset[i]
        # print(i,"ë²ˆì§¸")
    #     print(f"âœ… image shape: {img.shape}, dtype: {img.dtype}, range: ({img.min():.2f}, {img.max():.2f})")
    #     print(f"âœ… mask shape: {seg.shape}, unique values: {torch.unique(seg)}")
        all_labels.append(torch.unique(seg))

    flat = torch.cat(all_labels)
    print("\nğŸ’¡ ì „ì²´ ë¼ë²¨ ë¶„í¬ (ìƒìœ„ 10ê°œ ê¸°ì¤€):", torch.unique(flat))
