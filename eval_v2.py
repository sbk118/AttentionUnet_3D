import torch.nn.functional as F

# Softmax ê¸°ë°˜ Dice
# def dice_score(pred, target, epsilon=1e-6, exclude_class_0=True):
#     """
#     ë°°ê²½ì„ ì œì™¸í•˜ê³  dice score ì‚°ì¶œ
#     Args:
#         pred: [B, C, D, H, W] - model logits or probabilities (after softmax)
#         target: [B, D, H, W] - ground truth labels (0~C-1)
#     """
#     pred_soft = F.softmax(pred, dim=1)  # í™•ë¥ í™”
#     num_classes = pred.shape[1]
#
#     total_dice = 0
#     classes = range(1, num_classes) if exclude_class_0 else range(num_classes)
#
#     for cls in classes:
#         pred_cls = pred_soft[:, cls]
#         target_cls = (target == cls).float()
#
#         intersect = torch.sum(pred_cls * target_cls)
#         union = torch.sum(pred_cls) + torch.sum(target_cls)
#         dice = (2. * intersect + epsilon) / (union + epsilon)
#         total_dice += dice
#
#     return total_dice / len(classes)

def dice_score(pred, target, class_idx):
    pred_bin = (pred == class_idx)
    target_bin = (target == class_idx)
    intersection = (pred_bin & target_bin).sum().item()
    union = pred_bin.sum().item() + target_bin.sum().item()
    if union == 0:
        return 1.0  # ë‘˜ ë‹¤ ì—†ìŒ â†’ ì™„ë²½ížˆ ì¼ì¹˜
    return 2.0 * intersection / union

def iou_score(pred, target, class_idx):
    pred_bin = (pred == class_idx)
    target_bin = (target == class_idx)
    intersection = (pred_bin & target_bin).sum().item()
    union = (pred_bin | target_bin).sum().item()
    if union == 0:
        return 1.0
    return intersection / union

# dice_score() softmax ì œê±°
def dice_score_v2(pred_soft, target, epsilon=1e-6, exclude_class_0=True):
    """
    pred_soft: softmax ì ìš©ëœ í™•ë¥ ê°’ [B, C, D, H, W]
    """
    num_classes = pred_soft.shape[1]
    total_dice = 0
    classes = range(1, num_classes) if exclude_class_0 else range(num_classes)

    for cls in classes:
        pred_cls = pred_soft[:, cls]
        target_cls = (target == cls).float()

        intersect = (pred_cls * target_cls).sum()
        union = pred_cls.sum() + target_cls.sum()
        dice = (2. * intersect + epsilon) / (union + epsilon)
        total_dice += dice

    return total_dice / len(classes)

def multiclass_dice(pred, target, num_classes, exclude_class_0=True, epsilon=1e-6):
    """
    Multi-class Dice Score
    pred, target: shape (B, D, H, W) with integer class labels
    """
    classes = range(1, num_classes) if exclude_class_0 else range(num_classes)
    total_dice = 0.0

    for cls in classes:
        pred_cls = (pred == cls).float()
        target_cls = (target == cls).float()

        intersect = torch.sum(pred_cls * target_cls)
        union = torch.sum(pred_cls) + torch.sum(target_cls)
        dice = (2. * intersect + epsilon) / (union + epsilon)
        total_dice += dice

    return total_dice / len(classes)



# Argmax ê¸°ë°˜ Hard Dice
def classwise_dice(pred, target, num_classes=5):
    pred_soft = F.softmax(pred, dim=1)
    dice_per_class = []

    for cls in range(num_classes):
        pred_cls = pred_soft[:, cls]
        target_cls = (target == cls).float()

        intersect = torch.sum(pred_cls * target_cls)
        union = torch.sum(pred_cls) + torch.sum(target_cls)
        dice = (2. * intersect + 1e-6) / (union + 1e-6)
        dice_per_class.append(dice.item())

    return dice_per_class

"""
ðŸ”š ê²°ë¡ 
í›ˆë ¨ ì¤‘ loss ê³„ì‚° â†’ classwise_diceì™€ ê°™ì€ soft Dice ê¸°ë°˜ì´ ì¢‹ìŒ.

ì •í™•í•œ ì„±ëŠ¥ í‰ê°€ (inference í›„ ì„±ëŠ¥ ë¹„êµ ë“±) â†’ per_class_diceë¥¼ ì‚¬ìš©í•˜ëŠ” ê²Œ ì •í™•í•´.
"""

def per_class_dice(preds, masks, num_classes=5):
    """
    preds: [B, C, D, H, W] (logits)
    masks: [B, D, H, W] (ground truth)
    """
    pred_labels = torch.argmax(preds, dim=1)  # [B, D, H, W]
    dice_scores = []

    for cls in range(num_classes):
        pred_cls = (pred_labels == cls).float()
        gt_cls = (masks == cls).float()

        intersection = (pred_cls * gt_cls).sum()
        union = pred_cls.sum() + gt_cls.sum()
        dice = (2. * intersection) / (union + 1e-8)
        dice_scores.append(dice.item())

    return dice_scores




import torch
from tqdm import tqdm
from monai.transforms import Resize

def evaluate(model, dataloader, criterion, device):
    model.eval()
    total_loss = 0
    total_dice = 0
    num_batches = len(dataloader)

    loop = tqdm(dataloader, desc="ðŸ§ª Eval", leave=True)

    with torch.no_grad():
        for images, masks in loop:
            images, masks = images.to(device), masks.to(device)

            preds, _ = model(images)

            # sample-wise Resize (because monai.transforms.Resize doesn't support 5D directly)
            target_shape = list(masks.shape[-3:])  # (D, H, W)

            resize_fn = Resize(spatial_size=target_shape, mode="trilinear")
            preds_upsampled = torch.stack([
                resize_fn(p) for p in preds  # p: [C, D, H, W]
            ])

            # preds_upsampled = torch.stack([resize_fn(p.unsqueeze(0)).squeeze(0) for p in preds])

            preds_soft = torch.softmax(preds_upsampled, dim=1)  #> mainì˜ Crossentropyì—ì„œ softmaxê°€ ì§„í–‰ëœ ì±„ë¡œ ì „ë‹¬ëœë‹¤.
            loss = criterion(preds_upsampled, masks) #ëŠ” softmax ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            dice_v2 = dice_score_v2(preds_soft, masks) #ëŠ” clsê°’ ì‚¬ìš©

            total_loss += loss.item()
            total_dice += dice_v2.item()
            loop.set_postfix(loss=loss.item(), dice_v2=dice_v2.item())

    avg_loss = total_loss / num_batches
    avg_dice = total_dice / num_batches

    return avg_loss, avg_dice

#================================================
import os
import torch
import numpy as np
import nibabel as nib
from tqdm import tqdm

def eval_saved_predictions(pred_dir, gt_dir, num_classes=5):
    """
    ì €ìž¥ëœ prediction .nii.gz íŒŒì¼ê³¼ GTë¥¼ ë¹„êµí•˜ì—¬ Dice / IoU í‰ê°€ ë° ì„±ëŠ¥ ë“±ê¸‰í™”.

    Args:
        pred_dir: ì˜ˆì¸¡ ê²°ê³¼ .nii.gzê°€ ì €ìž¥ëœ ë””ë ‰í„°ë¦¬
        gt_dir: ground truthê°€ í¬í•¨ëœ BraTS directory
    """
    dice_all = []
    iou_all = []
    multiclass_dice_scores = []  # softmax ëŒ€ì‹  argmax ê¸°ë°˜ dice score

    # ì„±ëŠ¥ ë“±ê¸‰ë³„ ì¼€ì´ìŠ¤ ëª¨ìŒ
    high_score_cases = []   # Dice >= 0.9
    middle_score_cases = [] # 0.7 <= Dice < 0.9
    low_score_cases = []    # Dice <= 0.5

    pred_files = sorted([
        f for f in os.listdir(pred_dir)
        if f.endswith("-pred_upscaled.nii.gz")
    ])

    for idx, fname in enumerate(tqdm(pred_files, desc="ðŸ“Š Saved Evaluation")):
        case_id = fname.replace("-pred_upscaled.nii.gz", "")
        pred_path = os.path.join(pred_dir, fname)
        gt_path = os.path.join(gt_dir, case_id, f"{case_id}-seg.nii.gz")

        if not os.path.exists(pred_path) or not os.path.exists(gt_path):
            print(f"âŒ íŒŒì¼ ëˆ„ë½: {case_id}")
            continue

        pred = nib.load(pred_path).get_fdata().astype(np.int64)
        gt = nib.load(gt_path).get_fdata().astype(np.int64)

        # ì°¨ì› ì •ë¦¬
        pred = torch.tensor(pred).unsqueeze(0)  # [1, D, H, W]
        gt = torch.tensor(gt).unsqueeze(0)

        # classë³„ Dice/IoU
        dice_per_class = [dice_score(pred, gt, cls) for cls in range(num_classes)]
        iou_per_class = [iou_score(pred, gt, cls) for cls in range(num_classes)]
        dice_v2_score = multiclass_dice(pred, gt, num_classes)

        dice_all.append(dice_per_class)
        iou_all.append(iou_per_class)
        multiclass_dice_scores.append(dice_v2_score.item())

        # ë“±ê¸‰ ë¶„ë¥˜
        real_case_id = idx + 181  # ì˜ˆ: BraTS-PED-{case_id:05d}
        if dice_v2_score >= 0.9:
            high_score_cases.append((real_case_id, dice_v2_score.item()))
        elif dice_v2_score >= 0.7:
            middle_score_cases.append((real_case_id, dice_v2_score.item()))
        elif dice_v2_score < 0.51:
            low_score_cases.append((real_case_id, dice_v2_score.item()))

    # í‰ê·  ê³„ì‚°
    dice_all = np.array(dice_all)
    iou_all = np.array(iou_all)
    mean_dice = np.mean(dice_all, axis=0)
    mean_ious = np.mean(iou_all, axis=0)

    print("\nðŸ“Œ í‰ê·  Dice per class:", [round(d, 4) for d in mean_dice])
    print("ðŸ“Œ í‰ê·  IoU  per class:", [round(i, 4) for i in mean_ious])
    print("ðŸ“Œ í‰ê·  Dice_v2 (argmax ê¸°ë°˜):", np.mean(multiclass_dice_scores))

    # âœ… ì„±ëŠ¥ ë“±ê¸‰ ì¶œë ¥
    print("\nâœ… Dice 0.9 ì´ìƒì¸ Case ID ëª©ë¡:")
    print(high_score_cases)
    print("ë¹„ìœ¨:", round(len(high_score_cases) / len(multiclass_dice_scores) * 100, 2), "%")

    print("\nâœ… Dice 0.7 ì´ìƒì¸ Case ID ë¹„ìœ¨:")
    print(middle_score_cases)
    print(round(len(middle_score_cases) / len(multiclass_dice_scores) * 100, 2), "%")

    print("\nâŒ Dice 0.51 ë¯¸ë§Œì¸ Case ID ë¹„ìœ¨:")
    print(low_score_cases)
    print(round(len(low_score_cases) / len(multiclass_dice_scores) * 100, 2), "%")


if __name__ == "__main__":
    pred_dir = "./predictions/aug_v2"
    gt_dir = "./data/BraTS-PEDs2024_Training"
    eval_saved_predictions(pred_dir, gt_dir)